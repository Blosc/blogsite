<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blosc Main Blog Page </title><link>http://blosc.org/</link><description>Blosc, an extremely fast, multi-threaded, meta-compressor library</description><atom:link href="http://blosc.org/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2021 &lt;a href="mailto:blosc@blosc.org"&gt;The Blosc Developers&lt;/a&gt; </copyright><lastBuildDate>Fri, 09 Jul 2021 10:23:36 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title> Registering plugins in C-Blosc2</title><link>http://blosc.org/posts/registering-plugins/</link><dc:creator>Oscar Griñón</dc:creator><description>&lt;div&gt;&lt;p&gt;Blosc has traditionally supported different filters and codecs for compressing data,
and it was up to the user to choose one or another depending on her needs.
However, there will always be scenarios where a more richer variety of them could be useful.&lt;/p&gt;
&lt;p&gt;Blosc2 has now a new plugin register capability in place so that the info about the new filters and codecs can be persisted and transmitted to different machines.
In this way Blosc can figure out the info of persistent plugins, and use them so as to decompress the data without problems.&lt;/p&gt;
&lt;p&gt;Besides, the Blosc Development Team has implemented a centralized repository so that people can propose new plugins; and if these plugins fulfill a series of requirements, they will be officially accepted, and distributed &lt;em&gt;within&lt;/em&gt; the C-Blosc2 library.  This provides an easy path for extending C-Blosc2 and hence, better adapt to user needs.&lt;/p&gt;
&lt;p&gt;The plugins that can be registered in the repository can be either codecs or filters.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;A &lt;strong&gt;codec&lt;/strong&gt; is a program able to compress and decompress a data stream with the objective of reducing its size and to enable a faster transmission of data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A &lt;strong&gt;filter&lt;/strong&gt; is a program that reorders the data without changing its size, so that the initial and final size are equal. A filter consists of encoder and decoder.
The filter encoder is applied before the codec compressor (or codec encoder) in order to make data easier to compress
and the filter decoder is used after codec decompressor (or codec decoder) to restore the original data arrangement.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here it is an example on how the compression process goes:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_31c7d46f65624dd3b4bc41d8551bc5dd-1" name="rest_code_31c7d46f65624dd3b4bc41d8551bc5dd-1"&gt;&lt;/a&gt;&lt;span class="go"&gt;--------------------   filter encoder  -------------------   codec encoder   -------&lt;/span&gt;
&lt;a id="rest_code_31c7d46f65624dd3b4bc41d8551bc5dd-2" name="rest_code_31c7d46f65624dd3b4bc41d8551bc5dd-2"&gt;&lt;/a&gt;&lt;span class="go"&gt;|        src        |   -----------&amp;gt;  |        tmp        |   ----------&amp;gt;   | c_src |&lt;/span&gt;
&lt;a id="rest_code_31c7d46f65624dd3b4bc41d8551bc5dd-3" name="rest_code_31c7d46f65624dd3b4bc41d8551bc5dd-3"&gt;&lt;/a&gt;&lt;span class="go"&gt;--------------------                   -------------------                   -------&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;And the decompression process:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_2c889fce0bd946fdabde905da18e53f6-1" name="rest_code_2c889fce0bd946fdabde905da18e53f6-1"&gt;&lt;/a&gt;&lt;span class="go"&gt;--------   codec decoder    -------------------   filter decoder  -------------------&lt;/span&gt;
&lt;a id="rest_code_2c889fce0bd946fdabde905da18e53f6-2" name="rest_code_2c889fce0bd946fdabde905da18e53f6-2"&gt;&lt;/a&gt;&lt;span class="go"&gt;| c_src |   -----------&amp;gt;   |        tmp        |   ----------&amp;gt;   |        src        |&lt;/span&gt;
&lt;a id="rest_code_2c889fce0bd946fdabde905da18e53f6-3" name="rest_code_2c889fce0bd946fdabde905da18e53f6-3"&gt;&lt;/a&gt;&lt;span class="go"&gt;--------                    -------------------                   -------------------&lt;/span&gt;
&lt;/pre&gt;&lt;section id="register-for-user-plugins"&gt;
&lt;h2&gt;Register for user plugins&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;User registered plugins&lt;/strong&gt; are plugins that users register locally so that they can be used in the same way as Blosc official codecs and filters.
This option is perfect for users that want to try new filters or codecs on their own.&lt;/p&gt;
&lt;p&gt;The register process is quite simple.  You just use the &lt;code class="docutils literal"&gt;blosc2_register_filter()&lt;/code&gt; or &lt;code class="docutils literal"&gt;blosc2_register_codec()&lt;/code&gt; function and then the Blosc2 machinery
will store its info with the rest of plugins. After that you will be able to access your plugin through its ID by setting Blosc2 compression or decompression
params.&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-1" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-1"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                             filters pipeline&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-2" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-2"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-3" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-3"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |  BLOSC_SHUFFLE     1 |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-4" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-4"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-5" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-5"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |  BLOSC_BITSHUFFLE  2 |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-6" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-6"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-7" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-7"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |  BLOSC_DELTA       3 |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-8" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-8"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-9" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-9"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |  BLOSC_TRUNC       4 |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-10" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-10"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-11" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-11"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |         ...          |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-12" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-12"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-13" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-13"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |  BLOSC_NDCELL     32 |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-14" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-14"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-15" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-15"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |  BLOSC_NDMEAN     33 |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-16" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-16"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-17" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-17"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |         ...          |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-18" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-18"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-19" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-19"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |  urfilter1       160 |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-20" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-20"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-21" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-21"&gt;&lt;/a&gt;&lt;span class="go"&gt;blosc2_register_filter(urfilter2)  ---&amp;gt;  |  urfilter2       161 |  ---&amp;gt; cparams.filters[4] = 161; // can be used now&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-22" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-22"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-23" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-23"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                         |         ...          |&lt;/span&gt;
&lt;a id="rest_code_620c53df3495489e9f2b64cdcc80d30e-24" name="rest_code_620c53df3495489e9f2b64cdcc80d30e-24"&gt;&lt;/a&gt;&lt;span class="go"&gt;                                          ----------------------&lt;/span&gt;
&lt;/pre&gt;&lt;/section&gt;
&lt;section id="global-register-for-blosc-plugins"&gt;
&lt;h2&gt;Global register for Blosc plugins&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Blosc global registered plugins&lt;/strong&gt; are Blosc plugins that have passed through a selection process and a review by the Blosc Development Team.
These plugins will be available for everybody using the C-Blosc2 library.&lt;/p&gt;
&lt;p&gt;You should consider this option if you think that your codec or filter could be useful for the community, or you just want being able to use
them with upstream C-Blosc2 library.  The steps for registering an official Blosc plugin can be seen at:
&lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/main/plugins/README.md"&gt;https://github.com/Blosc/c-blosc2/blob/main/plugins/README.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some well documented examples of these kind of plugins are the codec &lt;code class="docutils literal"&gt;ndlz&lt;/code&gt; and the filters &lt;code class="docutils literal"&gt;ndcell&lt;/code&gt; and &lt;code class="docutils literal"&gt;ndmean&lt;/code&gt; on the C-Blosc2 GitHub repository:
&lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/tree/main/plugins"&gt;https://github.com/Blosc/c-blosc2/tree/main/plugins&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;section id="compiling-plugins-examples-using-blosc2-wheels"&gt;
&lt;h2&gt;Compiling plugins examples using Blosc2 wheels&lt;/h2&gt;
&lt;p&gt;So as to easy the use of the registered filters, full-fledged C-Blosc2 binary libraries including plugins functionality can be installed from
python-blosc2 (&amp;gt;= 0.1.8) wheels:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_568bc079eec74291861ccf61d7f2fa48-1" name="rest_code_568bc079eec74291861ccf61d7f2fa48-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;pip install blosc2
&lt;a id="rest_code_568bc079eec74291861ccf61d7f2fa48-2" name="rest_code_568bc079eec74291861ccf61d7f2fa48-2"&gt;&lt;/a&gt;&lt;span class="go"&gt;Collecting blosc2&lt;/span&gt;
&lt;a id="rest_code_568bc079eec74291861ccf61d7f2fa48-3" name="rest_code_568bc079eec74291861ccf61d7f2fa48-3"&gt;&lt;/a&gt;&lt;span class="go"&gt;  Downloading blosc2-0.1.8-cp37-cp37m-manylinux2010_x86_64.whl (3.3 MB)&lt;/span&gt;
&lt;a id="rest_code_568bc079eec74291861ccf61d7f2fa48-4" name="rest_code_568bc079eec74291861ccf61d7f2fa48-4"&gt;&lt;/a&gt;&lt;span class="go"&gt;     |████████████████████████████████| 3.3 MB 4.7 MB/s&lt;/span&gt;
&lt;a id="rest_code_568bc079eec74291861ccf61d7f2fa48-5" name="rest_code_568bc079eec74291861ccf61d7f2fa48-5"&gt;&lt;/a&gt;&lt;span class="go"&gt;Installing collected packages: blosc2&lt;/span&gt;
&lt;a id="rest_code_568bc079eec74291861ccf61d7f2fa48-6" name="rest_code_568bc079eec74291861ccf61d7f2fa48-6"&gt;&lt;/a&gt;&lt;span class="go"&gt;Successfully installed blosc2-0.1.8&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Once you have installed the C-Blosc2 libraries you can not only use the official Blosc filters and codecs, but you can also register and use them.
You can find directions on how to compile C files using the Blosc2 libraries inside these wheels at:
&lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/main/COMPILING_WITH_WHEELS.rst"&gt;https://github.com/Blosc/c-blosc2/blob/main/COMPILING_WITH_WHEELS.rst&lt;/a&gt;&lt;/p&gt;
&lt;section id="using-user-plugins"&gt;
&lt;h3&gt;Using user plugins&lt;/h3&gt;
&lt;p&gt;To use your own plugins with the Blosc machinery you first have to register them through the function &lt;code class="docutils literal"&gt;blosc2_register_codec()&lt;/code&gt; or &lt;code class="docutils literal"&gt;blosc2_register_filter()&lt;/code&gt;
with an ID between &lt;code class="docutils literal"&gt;BLOSC2_USER_DEFINED_FILTERS_START&lt;/code&gt; and &lt;code class="docutils literal"&gt;BLOSC2_USER_DEFINED_FILTERS_STOP&lt;/code&gt;. Then you can use this ID in the compression parameters (&lt;cite&gt;cparams.compcode&lt;/cite&gt;, &lt;cite&gt;cparams.filters&lt;/cite&gt;) and decompression parameters (&lt;cite&gt;dparams.compcode&lt;/cite&gt;, &lt;cite&gt;dparams.filters&lt;/cite&gt;).
For any doubts you can see the whole process in the examples &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/main/examples/urcodecs.c"&gt;urcodecs.c&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/main/examples/urfilters.c"&gt;urfilters.c&lt;/a&gt;.&lt;/p&gt;
&lt;pre class="code C"&gt;&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-1" name="rest_code_dcef8fb2a15c48449e155990fbd21891-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;blosc2_codec&lt;/span&gt; &lt;span class="n"&gt;urcodec&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-2" name="rest_code_dcef8fb2a15c48449e155990fbd21891-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;udcodec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compcode&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;244&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-3" name="rest_code_dcef8fb2a15c48449e155990fbd21891-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;udcodec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compver&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-4" name="rest_code_dcef8fb2a15c48449e155990fbd21891-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;udcodec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;complib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-5" name="rest_code_dcef8fb2a15c48449e155990fbd21891-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;udcodec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compname&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"urcodec"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-6" name="rest_code_dcef8fb2a15c48449e155990fbd21891-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;udcodec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;codec_encoder&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-7" name="rest_code_dcef8fb2a15c48449e155990fbd21891-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;udcodec&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;codec_decoder&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-8" name="rest_code_dcef8fb2a15c48449e155990fbd21891-8"&gt;&lt;/a&gt;&lt;span class="n"&gt;blosc2_register_codec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;urcodec&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-9" name="rest_code_dcef8fb2a15c48449e155990fbd21891-9"&gt;&lt;/a&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-10" name="rest_code_dcef8fb2a15c48449e155990fbd21891-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;blosc2_cparams&lt;/span&gt; &lt;span class="n"&gt;cparams&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BLOSC2_CPARAMS_DEFAULTS&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_dcef8fb2a15c48449e155990fbd21891-11" name="rest_code_dcef8fb2a15c48449e155990fbd21891-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;cparams&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compcode&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;244&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/section&gt;
&lt;section id="using-blosc-official-plugins"&gt;
&lt;h3&gt;Using Blosc official plugins&lt;/h3&gt;
&lt;p&gt;To use the Blosc official plugins it is mandatory to add the next lines in order to activate the plugins mechanism:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;#include &lt;span class="pre"&gt;"blosc2/codecs-registery.h"&lt;/span&gt;&lt;/code&gt; or &lt;code class="docutils literal"&gt;#include &lt;span class="pre"&gt;"blosc2/filters-registery.h"&lt;/span&gt;&lt;/code&gt; depending on the plugin type at the beginning of the file&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;#include "blosc2/blosc2.h"&lt;/code&gt; at the beginning of the file&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Call &lt;code class="docutils literal"&gt;blosc_init()&lt;/code&gt; at the beginning of main() function&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Call &lt;code class="docutils literal"&gt;blosc_destroy()&lt;/code&gt; at the end of main() function&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then you just have to use the ID of the plugin that you want to use in the compression parameters (&lt;code class="docutils literal"&gt;cparams.compcode&lt;/code&gt;).&lt;/p&gt;
&lt;pre class="code C"&gt;&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-1" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"blosc2.h"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-2" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"../codecs-registry.h"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-3" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-3"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-4" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;blosc_init&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-5" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;...&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-6" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-6"&gt;&lt;/a&gt;    &lt;span class="n"&gt;blosc2_cparams&lt;/span&gt; &lt;span class="n"&gt;cparams&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BLOSC2_CPARAMS_DEFAULTS&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-7" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;cparams&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compcode&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BLOSC_CODEC_NDLZ&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-8" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;cparams&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compcode_meta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-9" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-9"&gt;&lt;/a&gt;    &lt;span class="p"&gt;...&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-10" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;blosc_destroy&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_2d831973736c47e5b1d8eebffc5643ca-11" name="rest_code_2d831973736c47e5b1d8eebffc5643ca-11"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;In case of doubts, you can see how the whole process works in working tests like:
&lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/main/plugins/codecs/ndlz/test_ndlz.c"&gt;test_ndlz.c&lt;/a&gt;,
&lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/main/plugins/filters/ndcell/test_ndcell.c"&gt;test_ndcell.c&lt;/a&gt;,
&lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/main/plugins/filters/ndmean/test_ndmean_mean.c"&gt;test_ndmean_mean.c&lt;/a&gt; and
&lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/main/plugins/filters/ndmean/test_ndmean_repart.c"&gt;test_ndmean_repart.c&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="final-remarks"&gt;
&lt;h2&gt;Final remarks&lt;/h2&gt;
&lt;p&gt;The plugin register functionality let use new codecs and filters within Blosc in an easy and quick way. To enhance the plugin experience, we
have implemented a centralized plugin repository, so that users can propose their own plugins to be in the standard C-Blosc2 library for
the benefit of all the Blosc community.&lt;/p&gt;
&lt;p&gt;The Blosc Development Team kindly invites you to test the different plugins we already offer, but also to try with your own one.  Besides, if you are willing to contribute it to the community, then apply to register it. This way everyone will be able to enjoy a variety of different and unique plugins.  Hope you will enjoy this new and exciting feature!&lt;/p&gt;
&lt;p&gt;Last but not least, a big thank you to the NumFOCUS foundation for providing a grant for implementing the register functionality.&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>blosc plugins codecs filters</category><guid>http://blosc.org/posts/registering-plugins/</guid><pubDate>Mon, 28 Jun 2021 10:32:20 GMT</pubDate></item><item><title>Wrapping C-Blosc2 in Python (a beginner's view)</title><link>http://blosc.org/posts/python-blosc2-initial-release/</link><dc:creator>Marta Iborra</dc:creator><description>&lt;div&gt;&lt;p&gt;An initial release of the Python wrapper for
C-Blosc2 is now available in: &lt;a class="reference external" href="https://github.com/Blosc/python-blosc2"&gt;https://github.com/Blosc/python-blosc2&lt;/a&gt;.
In this blog I will try to explain some of the most difficult aspects that I had to learn in doing this
and how I solved them.&lt;/p&gt;
&lt;p&gt;This work is being made thanks to a grant from the Python Software Foundation.&lt;/p&gt;
&lt;section id="python-views"&gt;
&lt;h2&gt;Python views&lt;/h2&gt;
&lt;p&gt;At university, the first programming language that I learned was Python. But because programming was
new for the majority of the class the subject only covered the basics: basic statements and classes.
And although these were easy to understand, the views were unknown to me (until now).&lt;/p&gt;
&lt;p&gt;To explain what the views are, let’s suppose we have the following code in Python:&lt;/p&gt;
&lt;pre class="literal-block"&gt;&amp;gt;&amp;gt;&amp;gt; import sys
&amp;gt;&amp;gt;&amp;gt; a = []
&amp;gt;&amp;gt;&amp;gt; b = a
&amp;gt;&amp;gt;&amp;gt; sys.getrefcount(a)
3&lt;/pre&gt;
&lt;p&gt;The reference count for the object is 3: a, b and the argument passed to
sys.getrefcount().&lt;/p&gt;
&lt;p&gt;Basically, to avoid making copies of a same variable, Python uses views. Every variable has its counter and until the counter is 0, the variable is not deleted.
But that means that two threads cannot access the counter at the same time.  Because having a lock for every variable would be inefficient and could produce deadlocks (which means that several threads are waiting for each other), the GIL was created.  So GIL was my next thing to learn.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="gil-and-cython"&gt;
&lt;h2&gt;GIL and Cython&lt;/h2&gt;
&lt;p&gt;GIL stands for Global Interpreter Lock. With a single lock
on the interpreter there are no deadlocks. But the execution of any
Python program must acquire the interpreter lock, which prevents some
programs to take advantage of the multi-threading execution.&lt;/p&gt;
&lt;p&gt;When writing C extensions, this lock is very useful because
it can be released. Thus, the program can be more efficient (i.e.
threads can actually run in parallel).
To write a function with the GIL I spent many time reading about it.
Unfortunately, nothing seemed to expain what I wanted to do until
I found this nice
&lt;a class="reference external" href="http://nicolas-hug.com/blog/cython_notes#"&gt;blog&lt;/a&gt;
from
Nicolas Hug
in which he explains the 3 rules you have to follow to make Cython release the GIL.&lt;/p&gt;
&lt;p&gt;First of all, Cython needs to know which C functions that were imported are thread-safe.
This is done by using the &lt;cite&gt;nogil&lt;/cite&gt; statement in the function declaration.
Then, inside the function the &lt;cite&gt;with nogil&lt;/cite&gt; statement lets Cython know that this block is
going to be executed with the GIL released. But to make that code block safe,
there cannot be any Python interaction inside that block.&lt;/p&gt;
&lt;p&gt;To understand it better, an example is shown below:&lt;/p&gt;
&lt;pre class="literal-block"&gt;cdef extern from "math_operation.h":
    int add(int a, int b)nogil

cpdef sum(src, dest):
    cdef int len_src = len(src)
    cdef int len_dest = len(dest)
    cdef int result
    with nogil:
        # Code with the GIL released
        result = add(len_src, len_dest)
    # Code with the GIL, any Python interaction can be done here&lt;/pre&gt;
&lt;p&gt;The function &lt;cite&gt;sum&lt;/cite&gt; returns the result of adding the length of &lt;cite&gt;src&lt;/cite&gt; and &lt;cite&gt;dest&lt;/cite&gt;.
As you can see, the function has been defined with the &lt;cite&gt;cpdef&lt;/cite&gt; statement
instead of the &lt;cite&gt;def&lt;/cite&gt;. The &lt;cite&gt;c&lt;/cite&gt; lets Cython know that
this function can be called with C. So this is necessary when writing a
function with the GIL released, otherwise you will be trying to execute a Python
program without the GIL (which, as explained previously cannot be done).
Notice that &lt;cite&gt;len_src&lt;/cite&gt; and &lt;cite&gt;len_dest&lt;/cite&gt; have also been defined as C integers with the
&lt;cite&gt;cdef int&lt;/cite&gt; statement. If not, it would not be possible to work with them
with the GIL released (the &lt;cite&gt;with nogil&lt;/cite&gt; block).&lt;/p&gt;
&lt;p&gt;On the other hand, the &lt;cite&gt;p&lt;/cite&gt; lets Cython know that this function can be called through Python.
This does not have to be done always, only when you want to call that function from Python.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="cython-typed-memoryviews"&gt;
&lt;h2&gt;Cython typed memoryviews&lt;/h2&gt;
&lt;p&gt;One of the main differences between  the python-blosc
and python-blosc2 API, is that the functions &lt;cite&gt;compress_ptr&lt;/cite&gt;
and &lt;cite&gt;decompress_ptr&lt;/cite&gt; are no longer supported. We decided
to do so, because the Pickle protocol 5 already makes
an optimization of the copies. That way, we could have
a similar performance for &lt;cite&gt;compress_ptr&lt;/cite&gt;
and &lt;cite&gt;decompress_ptr&lt;/cite&gt; but with the functions &lt;cite&gt;pack&lt;/cite&gt;
and &lt;cite&gt;unpack&lt;/cite&gt;.&lt;/p&gt;
&lt;p&gt;However, when timing the functions I realised that
in the majority of the cases,
although
the &lt;cite&gt;compress&lt;/cite&gt; function from python-blosc2 was faster
than the &lt;cite&gt;compress_ptr&lt;/cite&gt;,
the
&lt;cite&gt;decompress&lt;/cite&gt; function was slower than the &lt;cite&gt;decompress_ptr&lt;/cite&gt;.
Thus I checked the code to see if the
speed could somehow be
increased.&lt;/p&gt;
&lt;p&gt;Originally, the code used the Python Buffer Protocol.
which is part of the Python/C API. The Python Buffer Protocol lets
you (among other things) obtain a
pointer to the raw data of an object. But because
it wasn't clear for me wether it needed to do a copy
or not
we decided to work with Cython typed memoryviews.&lt;/p&gt;
&lt;p&gt;Cython typed memoryviews are very similar to
Python memory views, but with the main difference
that the
first ones are a C-level type and therefore
they do not have much Python overhead.
Because it is a C-level type you have to know
the dimension of the buffer from which you want to
obtain
the typed memoryview as well as its data type.&lt;/p&gt;
&lt;p&gt;The shape dimension of the buffer is expressed writing
as many &lt;code class="docutils literal"&gt;:&lt;/code&gt; between brackets as dimensions it has.
If the memory is allocated contiguously, you can write
&lt;code class="docutils literal"&gt;::1&lt;/code&gt; instead in the corresponding dimension.
On the other hand, the type is expressed as you would
do it in Cython.
In the following code, you can see an example for a
one-dimensional numpy array:&lt;/p&gt;
&lt;pre class="literal-block"&gt;import numpy as np
arr = np.ones((10**6,), dtype=np.double)
cdef double [:] typed_view = arr&lt;/pre&gt;
&lt;p&gt;However, if you want to define a function that receives
an object whose type may be unknown,
you will have to create a
Python memoryview and then cast it into the
type you wish as in the next example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;# Get a Python memoryview from an object
mem_view = memoryview(object)
# Cast that memory view into an unsigned char memoryview
cdef unsigned char[:]typed_view = mem_view.cast('B')&lt;/pre&gt;
&lt;p&gt;The 'B' indicates to cast the memoryview type into an
unsigned char.&lt;/p&gt;
&lt;p&gt;But if I run the latter code for a binary Python string,
it produces a runtime error. It
took me 10 minutes to fix the error adding the
&lt;cite&gt;const&lt;/cite&gt; statement to the definition of the Cython
typed memoryview (as shown below), but I spent two
days trying to
understand the error and its solution.&lt;/p&gt;
&lt;pre class="literal-block"&gt;# Get a Python memoryview from an object
mem_view = memoryview(object)
# Cast that memory view into an unsigned char memoryview
cdef const unsigned char[:]typed_view = mem_view.cast('B')&lt;/pre&gt;
&lt;p&gt;The reason why the &lt;cite&gt;const&lt;/cite&gt; statement fixed it, is that a binary Python string is
a read-only buffer. By declaring the
typed memoryview to &lt;cite&gt;const&lt;/cite&gt;, Cython is being told that
the object from the memory view is a read-only buffer
so that it cannot change it.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusions"&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;So far, my experience wrapping &lt;cite&gt;C-Blosc2&lt;/cite&gt; has had
some ups and downs.&lt;/p&gt;
&lt;p&gt;One method that I use whenever I learn something new is
to write down a summary of what I read. Sometimes is almost a
copy (therefore some people may find it useless), but
it always works really well for me.
It helps me connect the ideas better or
to build a global idea of what I have or want to do.&lt;/p&gt;
&lt;p&gt;Another aspect I realized when doing this wrapper is that because
I am a stubborn person, I usually tend to
force myself to try to understand something and get frustrated
if I do not.
However,
I have to recognize that sometimes it is better to
forget about it until the next day. Your brain will organize
your ideas at night so that you can invest better your time
the next morning.&lt;/p&gt;
&lt;p&gt;But maybe the most difficult
part for me was the beginning, and therefore
I have to thank Francesc Alted and
Aleix Alcacer for giving me a push into the not always easy
world of Python extensions.&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>blosc2 python</category><guid>http://blosc.org/posts/python-blosc2-initial-release/</guid><pubDate>Mon, 10 May 2021 07:32:20 GMT</pubDate></item><item><title>C-Blosc2 Ready for General Review</title><link>http://blosc.org/posts/blosc2-ready-general-review/</link><dc:creator>Francesc Alted</dc:creator><description>&lt;div&gt;&lt;p&gt;On behalf of the Blosc team, we are happy to announce the &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/releases/tag/v2.0.0.rc1"&gt;first C-Blosc2
release (Release Candidate 1)&lt;/a&gt;
that is meant to be reviewed by users.  As of now
we are declaring both the API and the format frozen, and we are seeking for
feedback from the community so as to better check the library and declare it
apt for its use in production.&lt;/p&gt;
&lt;section id="some-history"&gt;
&lt;h2&gt;Some history&lt;/h2&gt;
&lt;p&gt;The next generation Blosc (aka Blosc2) started back in 2015 as a way
to overcome some limitations of the Blosc compressor, mainly the limitation
of 2 GB for the size of data to be compressed.  But it turned out that I wanted
to make thinks a bit more complete, and provide a native serialization too.
During that process Google awarded my contributions to Blosc with the
&lt;a class="reference external" href="https://www.blosc.org/posts/prize-push-Blosc2/"&gt;Open Source Peer Bonus Program&lt;/a&gt; in 2017.
This award represented a big emotional push for me in
persisting in the efforts towards producing a stable release.&lt;/p&gt;
&lt;p&gt;Back in 2018, Zeeman Wang from Huawei invited me to go to their central headquarters in Shenzhen to meet
a series of developers that were trying to use compression in a series of scenarios.
During two weeks we had a series of productive meetings, and I got aware of the many
possibilities that compression is opening in industry: since making phones with
limited hardware to work faster to accelerate computations on high-end computers.
That was also a great opportunity for me to better know a millennial culture; I was
genuinely interested to see how people live, eat and socialize in China.&lt;/p&gt;
&lt;p&gt;In 2020, &lt;a class="reference external" href="https://www.blosc.org/posts/blosc-donation/"&gt;Huawei graciously offered a grant to the Blosc project&lt;/a&gt; to complete the project.  Since then,
we have got donations from several other sources (like NumFOCUS, Python Software Foundation,
ESRF among them).  Lately &lt;a class="reference external" href="https://ironarray.io"&gt;ironArray&lt;/a&gt; is sponsoring
two of us (Aleix Alcacer and myself) to work partial time on Blosc related projects.&lt;/p&gt;
&lt;p&gt;Thanks to all this support, the Blosc development team has been able to grow quite a lot (we are currently 5 people in the core team) and we
have been able to work hard at producing a series of improvements in different projects under the Blosc umbrella, in particular &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2"&gt;C-Blosc2&lt;/a&gt;,
&lt;a class="reference external" href="https://github.com/Blosc/python-blosc2"&gt;Python-Blosc2&lt;/a&gt;,
&lt;a class="reference external" href="https://github.com/Blosc/caterva"&gt;Caterva&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/Blosc/cat4py"&gt;cat4py&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As you see, there is a lot of development going on around C-Blosc2 other than C-Blosc2 itself.  In this installment I am going to focus just on the main features that C-Blosc2 is bringing, but hopefully all the other projects in the ecosystem will also complement its existing functionality.  When all these projects would be ready, we hope that users will be able to use them to store big amounts of data in a way that is both efficient, easy-to-use and most importantly, adapted to their needs.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="new-features-of-c-blosc2"&gt;
&lt;h2&gt;New features of C-Blosc2&lt;/h2&gt;
&lt;p&gt;Here it is the list of the main features that we are releasing today:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;64-bit containers:&lt;/strong&gt; the first-class container in C-Blosc2 is the &lt;cite&gt;super-chunk&lt;/cite&gt; or, for brevity, &lt;cite&gt;schunk&lt;/cite&gt;, that is made by smaller chunks which are essentially C-Blosc1 32-bit containers.  The super-chunk can be backed or not by another container which is called a &lt;cite&gt;frame&lt;/cite&gt; (see later).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;More filters:&lt;/strong&gt; besides &lt;cite&gt;shuffle&lt;/cite&gt; and &lt;cite&gt;bitshuffle&lt;/cite&gt; already present in C-Blosc1, C-Blosc2 already implements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;delta&lt;/cite&gt;: the stored blocks inside a chunk are diff'ed with respect to first block in the chunk.  The idea is that, in some situations, the diff will have more zeros than the original data, leading to better compression.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;trunc_prec&lt;/cite&gt;: it zeroes the least significant bits of the mantissa of float32 and float64 types.  When combined with the &lt;cite&gt;shuffle&lt;/cite&gt; or &lt;cite&gt;bitshuffle&lt;/cite&gt; filter, this leads to more contiguous zeros, which are compressed better.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A filter pipeline:&lt;/strong&gt; the different filters can be pipelined so that the output of one can the input for the other.  A possible example is a &lt;cite&gt;delta&lt;/cite&gt; followed by &lt;cite&gt;shuffle&lt;/cite&gt;, or as described above, &lt;cite&gt;trunc_prec&lt;/cite&gt; followed by &lt;cite&gt;bitshuffle&lt;/cite&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Prefilters:&lt;/strong&gt; allows to apply user-defined C callbacks &lt;strong&gt;prior&lt;/strong&gt; the filter pipeline during compression.  See &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/master/tests/test_prefilter.c"&gt;test_prefilter.c&lt;/a&gt; for an example of use.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Postfilters:&lt;/strong&gt; allows to apply user-defined C callbacks &lt;strong&gt;after&lt;/strong&gt; the filter pipeline during decompression. The combination of prefilters and postfilters could be interesting for supporting e.g. encryption (via prefilters) and decryption (via postfilters).  Also, a postfilter alone can used to produce on-the-flight computation based on existing data (or other metadata, like e.g. coordinates). See &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/master/tests/test_postfilter.c"&gt;test_postfilter.c&lt;/a&gt; for an example of use.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;SIMD support for ARM (NEON):&lt;/strong&gt; this allows for faster operation on ARM architectures.  Only &lt;cite&gt;shuffle&lt;/cite&gt; is supported right now, but the idea is to implement &lt;cite&gt;bitshuffle&lt;/cite&gt; for NEON too.  Thanks to Lucian Marc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;SIMD support for PowerPC (ALTIVEC):&lt;/strong&gt; this allows for faster operation on PowerPC architectures.  Both &lt;cite&gt;shuffle&lt;/cite&gt;  and &lt;cite&gt;bitshuffle&lt;/cite&gt; are supported; however, this has been done via a transparent mapping from SSE2 into ALTIVEC emulation in GCC 8, so performance could be better (but still, it is already a nice improvement over native C code; see PR &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/pull/59"&gt;https://github.com/Blosc/c-blosc2/pull/59&lt;/a&gt; for details).  Thanks to Jerome Kieffer and &lt;a class="reference external" href="https://www.esrf.fr"&gt;ESRF&lt;/a&gt; for sponsoring the Blosc team in helping him in this task.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dictionaries:&lt;/strong&gt; when a block is going to be compressed, C-Blosc2 can use a previously made dictionary (stored in the header of the super-chunk) for compressing all the blocks that are part of the chunks.  This usually improves the compression ratio, as well as the decompression speed, at the expense of a (small) overhead in compression speed.  Currently, it is only supported in the &lt;cite&gt;zstd&lt;/cite&gt; codec, but would be nice to extend it to &lt;cite&gt;lz4&lt;/cite&gt; and &lt;cite&gt;blosclz&lt;/cite&gt; at least.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Contiguous frames:&lt;/strong&gt; allow to store super-chunks contiguously, either on-disk or in-memory.  When a super-chunk is backed by a frame, instead of storing all the chunks sparsely in-memory, they are serialized inside the frame container.  The frame can be stored on-disk too, meaning that persistence of super-chunks is supported.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sparse frames (on-disk):&lt;/strong&gt; each chunk in a super-chunk is stored in a separate file, as well as the metadata.  This is the counterpart of in-memory super-chunk, and allows for more efficient updates than in frames (i.e. avoiding 'holes' in monolithic files).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Partial chunk reads:&lt;/strong&gt; there is support for reading just part of chunks, so avoiding to read the whole thing and then discard the unnecessary data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Parallel chunk reads:&lt;/strong&gt; when several blocks of a chunk are to be read, this is done in parallel by the decompressing machinery.  That means that every thread is responsible to read, post-filter and decompress a block by itself, leading to an efficient overlap of I/O and CPU usage that optimizes reads to a maximum.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Meta-layers:&lt;/strong&gt; optionally, the user can add meta-data for different uses and in different layers.  For example, one may think on providing a meta-layer for &lt;a class="reference external" href="http://www.numpy.org"&gt;NumPy&lt;/a&gt; so that most of the meta-data for it is stored in a meta-layer; then, one can place another meta-layer on top of the latter for adding more high-level info if desired (e.g. geo-spatial, meteorological...).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Variable length meta-layers:&lt;/strong&gt; the user may want to add variable-length meta information that can be potentially very large (up to 2 GB). The regular meta-layer described above is very quick to read, but meant to store fixed-length and relatively small meta information.  Variable length metalayers are stored in the trailer of a frame, whereas regular meta-layers are in the header.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Efficient support for special values:&lt;/strong&gt; large sequences of repeated values can be represented with an efficient, simple and fast run-length representation, without the need to use regular codecs.  With that, chunks or super-chunks with values that are the same (zeros, NaNs or any value in general) can be built in constant time, regardless of the size.  This can be useful in situations where a lot of zeros (or NaNs) need to be stored (e.g. sparse matrices).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Nice markup for documentation:&lt;/strong&gt; we are currently using a combination of Sphinx + Doxygen + Breathe for documenting the C-API.  See &lt;a class="reference external" href="https://c-blosc2.readthedocs.io"&gt;https://c-blosc2.readthedocs.io&lt;/a&gt;.  Thanks to Alberto Sabater and Aleix Alcacer for contributing the support for this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Plugin capabilities for filters and codecs:&lt;/strong&gt; we have a plugin register capability inplace so that the info about the new filters and codecs can be persisted and transmitted to different machines.  Thanks to the NumFOCUS foundation for providing a grant for doing this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pluggable tuning capabilities:&lt;/strong&gt; this will allow users with different needs to define an interface so as to better tune different parameters like the codec, the compression level, the filters to use, the blocksize or the shuffle size.  Thanks to ironArray for sponsoring us in doing this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Support for I/O plugins:&lt;/strong&gt; so that users can extend the I/O capabilities beyond the current filesystem support.  Things like use databases or S3 interfaces should be possible by implementing these interfaces.  Thanks to ironArray for sponsoring us in doing this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Python wrapper:&lt;/strong&gt;  we have a preliminary wrapper in the works.  You can have a look at our ongoing efforts in the &lt;a class="reference external" href="https://github.com/Blosc/python-blosc2"&gt;python-blosc2 repo&lt;/a&gt;.  Thanks to the Python Software Foundation for providing a grant for doing this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Security:&lt;/strong&gt; we are actively using using the &lt;a class="reference external" href="https://github.com/google/oss-fuzz"&gt;OSS-Fuzz&lt;/a&gt; and &lt;a class="reference external" href="https://oss-fuzz.com"&gt;ClusterFuzz&lt;/a&gt; for uncovering programming errors in C-Blosc2.  Thanks to Google for sponsoring us in doing this.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As you see, the list is long and hopefully you will find compelling enough features for your own needs.  Blosc2 is not only about speed, but also about
providing&lt;/p&gt;
&lt;/section&gt;
&lt;section id="tasks-to-be-done"&gt;
&lt;h2&gt;Tasks to be done&lt;/h2&gt;
&lt;p&gt;Even if the list of features above is long, we still have things to do in Blosc2; and the plan is to continue the development, although always respecting the existing API and format.  Here are some of the things in our TODO list:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Centralized plugin repository:&lt;/strong&gt; we have got a grant from NumFOCUS for implementing a centralized repository so that people can send their plugins (using the existing machinery) to the Blosc2 team.  If the plugins fulfill a series of requirements, they will be officially accepted, and distributed withing the library.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Improve the safety of the library:&lt;/strong&gt;  although this is always a work in progress, we did a long way in improving our safety, mainly thanks to the efforts of Nathan Moinvaziri.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Support for lossy compression codecs:&lt;/strong&gt; although we already support the &lt;cite&gt;trunc_prec&lt;/cite&gt; filter, this is only valid for floating point data; we should come with lossy codecs that are meant for any data type.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Checksums:&lt;/strong&gt; the frame can benefit from having a checksum per every chunk/index/metalayer.  This will provide more safety towards frames that are damaged for whatever reason.  Also, this would provide better feedback when trying to determine the parts of the frame that are corrupted.  Candidates for checksums can be the xxhash32 or xxhash64, depending on the goals (to be decided).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Documentation:&lt;/strong&gt; utterly important for attracting new users and making the life easier for existing ones.  Important points to have in mind here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Quality of API docstrings:&lt;/strong&gt; is the mission of the functions or data structures clearly and succinctly explained? Are all the parameters explained?  Is the return value explained?  What are the possible errors that can be returned?.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Tutorials/book:&lt;/strong&gt; besides the API docstrings, more documentation materials should be provided, like tutorials or a book about Blosc (or at least, the beginnings of it).  Due to its adoption in GitHub and Jupyter notebooks, one of the most extended and useful markup systems is Markdown, so this should also be the first candidate to use here.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Lock support for super-chunks:&lt;/strong&gt; when different processes are accessing concurrently to super-chunks, make them to sync properly by using locks, either on-disk (frame-backed super-chunks), or in-memory. Such a lock support would be configured in build time, so it could be disabled with a cmake flag.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It would be nice that, in case some of this feature (or a new one) sounds useful for you, you can help us in providing either code or sponsorship.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Since 2015, it has been a long time to get C-Blosc2 so much featured and tested.
But hopefully the journey will continue because as &lt;a class="reference external" href="https://www.poetryfoundation.org/poems/51296/ithaka-56d22eef917ec"&gt;Kavafis said&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;As you set out for Ithaka
hope your road is a long one,
full of adventure, full of discovery.&lt;/pre&gt;
&lt;p&gt;Let me thank again all the people and sponsors that we have had during the life of the Blosc project; without them we would not be where we are now.  We do hope that C-Blosc2 will have a long life and we as a team will put our soul in making that trip to last as long as possible.&lt;/p&gt;
&lt;p&gt;Now is your turn.  We expect you to start testing the library as much as possible and report back.  With your help we can get C-Blosc2 in production stage hopefully very soon.  Thanks in advance!&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>blosc2 release candidate</category><guid>http://blosc.org/posts/blosc2-ready-general-review/</guid><pubDate>Thu, 06 May 2021 10:32:20 GMT</pubDate></item><item><title>Blosc metalayers, where the user metainformation is stored</title><link>http://blosc.org/posts/blosc-metalayers/</link><dc:creator>Aleix Alcacer</dc:creator><description>&lt;div&gt;&lt;p&gt;The C-Blosc2 library has two different spaces to store user-defined information.
In this post, we are going to describe what these spaces are and where they are
stored inside a Blosc2 frame (a persistent super-chunk).&lt;/p&gt;
&lt;p&gt;As its name suggests, a metalayer is a space that allows users to store custom information.
For example, &lt;a class="reference external" href="https://github.com/Blosc/Caterva"&gt;Caterva&lt;/a&gt;, a project based on C-Blosc2 that handles
compressed and chunked arrays, uses these metalayers to store the dimensions and
the shape, chunkshape and blockshape of the arrays.&lt;/p&gt;
&lt;section id="fixed-length-metalayers"&gt;
&lt;h2&gt;Fixed-length metalayers&lt;/h2&gt;
&lt;p&gt;The first kind of metalayers in Blosc2 are the fixed-length metalayers.
These metalayers are stored in the header of the frame.
This decision allows adding chunks to the frame without the need to
rewrite the whole meta information and data coming after it.&lt;/p&gt;
&lt;p&gt;But this implementation has some drawbacks. The most important one is that
fixed-length metalayers cannot be resized.  Furthermore, once the first chunk of data is added
to the super-chunk, no more fixed-length metalayers can be added either.&lt;/p&gt;
&lt;p&gt;Let's see with an example the reason for these restrictions. Supose that we
have a frame that stores 10 GB of data with a metalayer containing a "cat".
If we update the meta information with a "dog" we can do that because they
have exactly the same size.&lt;/p&gt;
&lt;p&gt;However, if we were to update the meta information with a "giraffe", the
metalayer would need to be resized and therefore we would have to rewrite
the 10GB of data plus the trailer.
This would obviously be very inefficient and hence, not allowed:&lt;/p&gt;
&lt;figure&gt;
&lt;img alt="/images/metalayers/metalayers.png" src="http://blosc.org/images/metalayers/metalayers.png"&gt;
&lt;figcaption&gt;
&lt;p&gt;Data that would need to be rewritten are ploted in red.&lt;/p&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/section&gt;
&lt;section id="variable-length-metalayers"&gt;
&lt;h2&gt;Variable-length metalayers&lt;/h2&gt;
&lt;p&gt;To fix the above issue, we have introduced variable-length metalayers.
Unlike fixed-length metalayers, these are stored in the trailer
section of the frame.&lt;/p&gt;
&lt;p&gt;As their name suggests, these metalayers can be resized. Blosc can do that because,
whenever the metalayers content are modified, Blosc rewrites the trailer completely,
using more space if necessary.  Furthermore, and since these metalayers are stored in the trailer,
they will also be rewritten each time a chunk is added.&lt;/p&gt;
&lt;p&gt;Another feature of variable-length metalayers is that their content is
compressed by default (in contrast to fixed-length metalayers).
This will minimize the size of the trailer, a very important feature
because since the trailer is rewritten every time new data is added, we
want to keep it as small as possible so as to optimize data written.&lt;/p&gt;
&lt;p&gt;Let's continue with the previous example, but storing the meta
information in a variable-length metalayer now:&lt;/p&gt;
&lt;figure&gt;
&lt;img alt="/images/metalayers/metalayers-vl.png" src="http://blosc.org/images/metalayers/metalayers-vl.png"&gt;
&lt;/figure&gt;
&lt;p&gt;In this case the trailer is rewritten each time that we update the metalayer,
but it is a much more efficient operation than rewriting all the data (as a fixed-length metalayer would require).
So the variable-length metalayers complement the fixed-length metalayers by bringing different capabilities on the table.
Depending on her needs, it is up to the user to choose one or another metalayer storage.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="fixed-length-vs-variable-length-metalayers-comparsion"&gt;
&lt;h2&gt;Fixed-length vs variable-length metalayers comparsion&lt;/h2&gt;
&lt;p&gt;To summarize, and to better see what kind of metalayer is more suitable
for each situation, the following table contains a comparison between fixed-length
metalayers and variable-length metalayers:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style="width: 42%"&gt;
&lt;col style="width: 27%"&gt;
&lt;col style="width: 30%"&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;Fixed-length metalayers&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;Variable-length metalayers&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Where are stored?&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;Header&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;Trailer&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Can be resized?&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;No&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;Yes&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Can be added after adding chunks?&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;No&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;Yes&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Are they rewritten when adding chunks?&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;No&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;Yes&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/section&gt;
&lt;section id="metalayers-api"&gt;
&lt;h2&gt;Metalayers API&lt;/h2&gt;
&lt;p&gt;Currently, C-Blosc2 has the following functions implemented:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;blosc2_meta_add()&lt;/code&gt; / &lt;code class="docutils literal"&gt;blosc2_vlmeta_add()&lt;/code&gt;: Add a new metalayer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;blosc2_meta_get()&lt;/code&gt; / &lt;code class="docutils literal"&gt;blosc2_vlmeta_get()&lt;/code&gt;: Get the metalayer content.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;blosc2_meta_exists()&lt;/code&gt; / &lt;code class="docutils literal"&gt;blosc2_vlmeta_exists()&lt;/code&gt;: Check if a metalayer exists or not.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;blosc2_meta_update()&lt;/code&gt; / &lt;code class="docutils literal"&gt;blosc2_vlmeta_update()&lt;/code&gt;: Update the metalayer content.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="conclusions"&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;As we have seen, Blosc2 supports two different spaces where users can store
their meta information.  The user can choose one or another depending on her needs.&lt;/p&gt;
&lt;p&gt;On the one hand, the fixed-length metalayers are meant to store user meta
information that does not change size over time.
They are stored in the header and can be updated without having to rewrite any
other part of the frame, but they can no longer be added once the first chunk
of data is added.&lt;/p&gt;
&lt;p&gt;On the other hand, for users storing meta information that is going to change in size over time,
they can store their meta information into variable-length metalayers.  These
are stored in the trailer section of a frame and are more flexible
than its fixed-length counterparts.  However, each time that a metalayer content is
updated, the whole trailer has to be rewritten.&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>blosc2 metalayers</category><guid>http://blosc.org/posts/blosc-metalayers/</guid><pubDate>Fri, 05 Mar 2021 07:32:20 GMT</pubDate></item><item><title>Introducing Sparse Frames</title><link>http://blosc.org/posts/introducing-sparse-frames/</link><dc:creator>Marta Iborra</dc:creator><description>&lt;div&gt;&lt;section id="overview"&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/pull/176"&gt;new sparse frame implementation&lt;/a&gt;
allows the storage of Blosc2 super-chunk data chunks sparsely on-disk, using the filesystem as a key/value storage.
This mimics existing formats like &lt;a class="reference external" href="https://github.com/Blosc/bcolz/blob/master/DISK_FORMAT_v1.rst"&gt;bcolz&lt;/a&gt;
or &lt;a class="reference external" href="https://zarr.readthedocs.io/en/stable/spec/v2.html"&gt;Zarr&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the sparse implementation we are making use of the existing &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/master/README_CFRAME_FORMAT.rst"&gt;contiguous frame&lt;/a&gt;,
in order to store the metadata and the index for accessing the different chunks.
Here you can see the new sparse format compared with the existing contiguous frame:&lt;/p&gt;
&lt;img alt="/images/sparse-frames/cframe-vs-sframe.png" class="align-center" src="http://blosc.org/images/sparse-frames/cframe-vs-sframe.png" style="width: 70%;"&gt;
&lt;p&gt;As can be seen in the image above, the contiguous frame file is made of
a header, a chunks section and a trailer.
The header contains information needed to decompress the chunks and the
trailer contains a user meta data chunk.
The chunks section for a contiguous frame is made of all the data chunks plus the index chunk.
The latter contains the offset where each chunk begins inside the contiguous frame.
All these pieces are stored sequentially, without any empty spaces between them.&lt;/p&gt;
&lt;p&gt;However, in a sparse frame the chunks are stored somewhere as independent binary files.
But there is still the need to store the information to decompress the chunks as well as
a place to store the user meta data.  All this goes to the &lt;cite&gt;chunks.b2frame&lt;/cite&gt;, which is
actually a contiguous frame file with the difference that its chunks section contains only
the index chunk.  This index chunk stores the ID of each chunk (an integer from 0 to 2^32-1).
The name of the chunk file is built by expressing the chunk ID in hexadecimal,
padded with zeros (until 8 characters) and adding the &lt;cite&gt;.chunk&lt;/cite&gt; extension.
For example, if the index chunk is 46 (2E in hexadecimal) the chunk file name would
be &lt;cite&gt;0000002E.chunk&lt;/cite&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="advantages"&gt;
&lt;h2&gt;Advantages&lt;/h2&gt;
&lt;p&gt;The big advantage of the sparse frame compared with the contiguous one is
avoiding empty spaces resulting when updating a chunk.&lt;/p&gt;
&lt;p&gt;To better illustrate this, let's imagine that the set of the data chunks in
a contiguous frame is stored like in the
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Jenga"&gt;Jenga board game tower&lt;/a&gt;, a tower
built with wood blocks.  But in constrast to the genuine
&lt;cite&gt;Jenga board game&lt;/cite&gt;, not all the blocks have the same size (the uncompressed
size of a the chunks is the same, but not the compressed one):&lt;/p&gt;
&lt;figure class="align-center"&gt;
&lt;img alt="/images/sparse-frames/jenga3.png" src="http://blosc.org/images/sparse-frames/jenga3.png" style="width: 50%;"&gt;
&lt;/figure&gt;
&lt;p&gt;Above it is shown the initial structure of such a tower. If the yellow piece
is updated (changed by another piece) there are two possibilities.
The first one is that the new piece fits into the empty space left where
the old piece was. In that case, the new piece is put in the previous space
without any problem and we have no empty spaces left.  However, if the new piece
does not fit into the empty space, the new piece has to be placed at the
top of the tower (like in the game), leaving an empty space where the old piece was.&lt;/p&gt;
&lt;p&gt;On the other hand, the chunks of an sparse frame can be seen as books on a shelf, where
each book is a different chunk:&lt;/p&gt;
&lt;img alt="/images/sparse-frames/bookshelf.png" class="align-center" src="http://blosc.org/images/sparse-frames/bookshelf.png" style="width: 50%;"&gt;
&lt;p&gt;If one needs to update one book with
the new, taller edition, one only has to grab the old edition and replace it by the new one.
As there is no limit in the height of the books, the yellow book can be replaced with a
larger book without creating empty spaces, and making a better use of space.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="example-of-use"&gt;
&lt;h2&gt;Example of use&lt;/h2&gt;
&lt;p&gt;Creating a sparse frame in C-Blosc2 is easy; just specifify the name of the directory where
you want to store your chunks and you are done:&lt;/p&gt;
&lt;pre class="literal-block"&gt;blosc2_storage storage = {.urlpath="dir1.b2frame"};
schunk = blosc2_schunk_new(storage);
for (nchunk = 0; nchunk &amp;lt; NCHUNKS; nchunk++) {
    blosc2_schunk_append_buffer(schunk, data, isize);
}&lt;/pre&gt;
&lt;p&gt;The above will create NCHUNKS of chunks in the "dir.b2frame".  After that, you can open and read
the frame with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;schunk = blosc2_schunk_open("dir1.b2frame");
for (nchunk = 0; nchunk &amp;lt; NCHUNKS; nchunk++) {
    blosc2_schunk_decompress_chunk(schunk, nchunk, data_dest, isize);
}&lt;/pre&gt;
&lt;p&gt;Simple and effective.&lt;/p&gt;
&lt;p&gt;You can have a look at a &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/master/examples/sframe_simple.c"&gt;more complete example here&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="future-work"&gt;
&lt;h2&gt;Future work&lt;/h2&gt;
&lt;p&gt;We think that this implementation opens the door to several interesting possibilities.&lt;/p&gt;
&lt;p&gt;For example, by introducing networking code in Blosc2,
the chunks could be stored in another machine and accessed remotely.
That way, with just the metadata (the contiguous frame) we could
access all the data chunks in the sparse frame.&lt;/p&gt;
&lt;p&gt;For example, let's suppose that we have a sparse frame with 1 million chunks.
The total size of the data chunks from this sparse frame is 10 TB, but the
contiguous frame size can be as small as 10 KB.  So, with just sending an
small object of 10 KB, any worker could access the whole 10 TB of data.&lt;/p&gt;
&lt;p&gt;The remote stores could be typical networked key/value databases. The key is the identifier
for each element of the database, whereas the value is the information that is associated
to each key (similar to a set of unique keys and a set of doors). In this case, the key would
be built from the metadata (e.g. a URL) plus the index of the chunk, and the value would be
the data chunk itself.&lt;/p&gt;
&lt;p&gt;This can lead to a whole new range of applications, where data can be spread in the
cloud and workers can access to it by receiving small amounts of serialized buffers (the
contiguous frame).  This way, arbitrarily large data silos could be created and accessed
via the C-Blosc2 library (plus a key/value network store).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note by Francesc&lt;/em&gt;: The implementation of sparse frames has been done by Marta Iborra, who
is the main author of this blog too.  Marta joined the Blosc team a few months ago as a student,
and the whole team is very pleased with the quality of her contribution; we would be thrilled
to continue having her among us for the next months (but this requires some budget indeed).
If you like where we are headed, please consider making a donation
to the Blosc project via the NumFOCUS Foundation: &lt;a class="reference external" href="https://blosc.org/pages/donate"&gt;https://blosc.org/pages/donate&lt;/a&gt;.  Thank you!&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>blosc2 sparse frame format</category><guid>http://blosc.org/posts/introducing-sparse-frames/</guid><pubDate>Mon, 08 Feb 2021 07:32:20 GMT</pubDate></item><item><title>Announcing Blosc Wheels</title><link>http://blosc.org/posts/new-blosc-wheels/</link><dc:creator>Oscar Guiñón</dc:creator><description>&lt;div&gt;&lt;p&gt;We are happy to announce that wheels for Intel (32 and 64 bits) and all major OS (Win, Linux, Mac) are being produced on regular basis for python-blosc.  Such wheels also contain development files for the C-Blosc library.  If you are interested in knowing more how to use them, keep reading.&lt;/p&gt;
&lt;p&gt;A Python wheel (.whl file) is a ZIP archive used to make easier the installation process of packages.  The new wheels make Blosc library installation faster by avoiding compiling, and they are now available at PyPI. See: &lt;a class="reference external" href="https://pypi.org/project/blosc/"&gt;https://pypi.org/project/blosc/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Moreover, wheels for Blosc have support for AVX2 &lt;em&gt;runtime&lt;/em&gt; detection, so it will be automatically leveraged in case the local host has AVX2. On the other hand, if the host does not have AVX2, SSE2 is used instead, which, even if it is slower than AVX2, it is still faster than regular x86 instructions.&lt;/p&gt;
&lt;section id="small-intro-to-wheels"&gt;
&lt;h2&gt;Small intro to wheels&lt;/h2&gt;
&lt;p&gt;Wheels are an advantageous alternative to distribute Python (but also pure C) packages which contain C (or Cython) source code, and hence, need a compiler.  For those that are not familiar to wheels, here it comes a small tutorial on how to create and use wheels.&lt;/p&gt;
&lt;p&gt;First, let's recall the traditional way to build a source distribution:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_c9df7a51893d4392817f22618075c42c-1" name="rest_code_c9df7a51893d4392817f22618075c42c-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;python setup.py sdist
&lt;/pre&gt;&lt;p&gt;To build a wheel, the process is quite similar:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_8aeaf65d2a9945f9bfbcfc1b881fdb82-1" name="rest_code_8aeaf65d2a9945f9bfbcfc1b881fdb82-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;python setup.py bdist_wheel
&lt;/pre&gt;&lt;p&gt;To install a package via pip (pip decides whether install a from wheel or compile from the source package; wheels have obviously more priority):&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_0a19cdae1bcf488cb824dffbcdbbebde-1" name="rest_code_0a19cdae1bcf488cb824dffbcdbbebde-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;python -m pip install &lt;span class="o"&gt;{&lt;/span&gt;package&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;To install a package forcing to use source distribution:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_5ba3f45ad658429c93df2737370aa650-1" name="rest_code_5ba3f45ad658429c93df2737370aa650-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;python -m pip install --no-binary &lt;span class="o"&gt;{&lt;/span&gt;package&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;To install a package forcing to use wheels:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_22af016e3af84a1b805b10115bf1499d-1" name="rest_code_22af016e3af84a1b805b10115bf1499d-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;python -m pip install --only-binary &lt;span class="o"&gt;{&lt;/span&gt;package&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/section&gt;
&lt;section id="different-types-of-wheels"&gt;
&lt;h2&gt;Different types of wheels&lt;/h2&gt;
&lt;p&gt;There are different kind of wheels, depending on the goals and the build process:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Universal Wheels are wheels that are pure Python (i.e. contain no compiled extensions) and support Python 2 and 3.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Pure Python Wheels that are not “universal” are wheels that are pure Python (i.e. contain no compiled extensions), but don’t natively support both Python 2 and 3.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Platform Wheels are wheels that are specific to a certain platform like Linux, macOS, or Windows, usually due to containing compiled extensions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Platform wheels are built in one Linux variant and have no guarantee of working on another Linux variant.  However, the manylinux wheels are accepted by most Linux variants:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;manylinux1: based on Centos5.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;manylinux2010: based on Centos6.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;manylinux2014: based on Centos7.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Specifically, Blosc wheels are platform wheels that support Python3 (3.7 and up) on Windows, Linux and Mac, for both 32 and 64 bits systems.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="binaries-for-c-blosc-libraries-are-included"&gt;
&lt;h2&gt;Binaries for C-Blosc libraries are included&lt;/h2&gt;
&lt;p&gt;Although wheels were meant for Python packages, nothing prevents adding more stuff to them.  In particular, we are not only distributing python-blosc binary extensions in our wheels, but also binaries for the C-Blosc library.  This way, people willing to use the C-Blosc library can make use of these wheels to install the necessary development files.&lt;/p&gt;
&lt;p&gt;First, install the binary wheel via PyPI without the need to manually compile the thing:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_c15d5197f6da48ab8214aa90492ccc78-1" name="rest_code_c15d5197f6da48ab8214aa90492ccc78-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;pip install --only-binary blosc
&lt;/pre&gt;&lt;p&gt;Now, let's suppose that we want to compile the &lt;cite&gt;c-blosc/examples/many_compressors.c&lt;/cite&gt; on Linux:&lt;/p&gt;
&lt;p&gt;First, you have to look where the wheels directory is located.  In our case:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_bb05fcfd01a14543a1fe3a2b7ee9143a-1" name="rest_code_bb05fcfd01a14543a1fe3a2b7ee9143a-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;&lt;span class="nv"&gt;WHEEL_DIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/home/soscar/miniconda3
&lt;a id="rest_code_bb05fcfd01a14543a1fe3a2b7ee9143a-2" name="rest_code_bb05fcfd01a14543a1fe3a2b7ee9143a-2"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$WHEEL_DIR&lt;/span&gt;/lib   &lt;span class="c1"&gt;# note that you need the LD_LIBRARY_PATH env variable&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;For the actual compilation, you need to pass the directory for the include and lib directories:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_96fe57dd448c4812b1a8468686598b09-1" name="rest_code_96fe57dd448c4812b1a8468686598b09-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;gcc many_compressors.c -I&lt;span class="nv"&gt;$WHEEL_DIR&lt;/span&gt;/include -o many_compressors -L&lt;span class="nv"&gt;$WHEEL_DIR&lt;/span&gt;/lib -lblosc
&lt;/pre&gt;&lt;p&gt;Finally, run the resulting binary and hopefully you will see something like:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-1" name="rest_code_8982303deb26406a8c5b8e337a576f0f-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$ &lt;/span&gt;./many_compressors
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-2" name="rest_code_8982303deb26406a8c5b8e337a576f0f-2"&gt;&lt;/a&gt;&lt;span class="go"&gt;Blosc version info: 1.20.1 ($Date:: 2020-09-08 #$)&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-3" name="rest_code_8982303deb26406a8c5b8e337a576f0f-3"&gt;&lt;/a&gt;&lt;span class="go"&gt;Using 4 threads (previously using 1)&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-4" name="rest_code_8982303deb26406a8c5b8e337a576f0f-4"&gt;&lt;/a&gt;&lt;span class="go"&gt;Using blosclz compressor&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-5" name="rest_code_8982303deb26406a8c5b8e337a576f0f-5"&gt;&lt;/a&gt;&lt;span class="go"&gt;Compression: 4000000 -&amp;gt; 37816 (105.8x)&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-6" name="rest_code_8982303deb26406a8c5b8e337a576f0f-6"&gt;&lt;/a&gt;&lt;span class="go"&gt;Succesful roundtrip!&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-7" name="rest_code_8982303deb26406a8c5b8e337a576f0f-7"&gt;&lt;/a&gt;&lt;span class="go"&gt;Using lz4 compressor&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-8" name="rest_code_8982303deb26406a8c5b8e337a576f0f-8"&gt;&lt;/a&gt;&lt;span class="go"&gt;Compression: 4000000 -&amp;gt; 37938 (105.4x)&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-9" name="rest_code_8982303deb26406a8c5b8e337a576f0f-9"&gt;&lt;/a&gt;&lt;span class="go"&gt;Succesful roundtrip!&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-10" name="rest_code_8982303deb26406a8c5b8e337a576f0f-10"&gt;&lt;/a&gt;&lt;span class="go"&gt;Using lz4hc compressor&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-11" name="rest_code_8982303deb26406a8c5b8e337a576f0f-11"&gt;&lt;/a&gt;&lt;span class="go"&gt;Compression: 4000000 -&amp;gt; 27165 (147.2x)&lt;/span&gt;
&lt;a id="rest_code_8982303deb26406a8c5b8e337a576f0f-12" name="rest_code_8982303deb26406a8c5b8e337a576f0f-12"&gt;&lt;/a&gt;&lt;span class="go"&gt;Succesful roundtrip!&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;For more details, including compiling with binary wheels on other platforms than Linux, see: &lt;a class="reference external" href="https://github.com/Blosc/c-blosc/blob/master/COMPILING_WITH_WHEELS.rst"&gt;https://github.com/Blosc/c-blosc/blob/master/COMPILING_WITH_WHEELS.rst&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="final-remarks"&gt;
&lt;h2&gt;Final remarks&lt;/h2&gt;
&lt;p&gt;Producing Python wheels for a project can be somewhat involved for regular users. However, the advantages of binary wheels really make them worth the effort, since they make the installation process easier and faster for users.  This is why we are so happy to finally provide wheels that can benefit, not only python-blosc users, but users of the C-Blosc library as well.&lt;/p&gt;
&lt;p&gt;Last but not least, a big thank you to the Zarr team, specially to Jeff Hammerbacher, who provided a grant to the Blosc team for making the wheels support official.  Hopefully this new development will make life easier for Zarr developers and users (by the way, we are really glad to see Zarr quickly spreading as a data container for big multidimensional data, and Blosc helping on the compression part).&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>wheels</category><guid>http://blosc.org/posts/new-blosc-wheels/</guid><pubDate>Mon, 18 Jan 2021 12:32:20 GMT</pubDate></item><item><title>Mid 2020 Progress Report</title><link>http://blosc.org/posts/mid-2020-progress-report/</link><dc:creator>Francesc Alted</dc:creator><description>&lt;div&gt;&lt;p&gt;2020 has been a year where the Blosc projects have received important donations, totalling an amount of $55,000 USD so far.  In the present report we list the most important tasks that have been carried out during the period that goes from January 2020 to August 2020.  Most of these tasks are related to the most fast-paced projects under development: C-Blosc2 and Caterva (including its cat4py wrapper).  Having said that, the Blosc development team has been active in other projects too (C-Blosc, python-blosc), although mainly for maintenance purposes.&lt;/p&gt;
&lt;p&gt;Besides, we also list the roadmap for the C-Blosc2, Caterva and cat4py projects that we plan to tackle during the next few months.&lt;/p&gt;
&lt;section id="c-blosc2"&gt;
&lt;h2&gt;C-Blosc2&lt;/h2&gt;
&lt;p&gt;C-Blosc2 adds new data containers, called superchunks, that are essentially a set of compressed chunks in memory that can be accessed randomly and enlarged during its lifetime.  Also, a new frame serialization layer has been added, so that superchunks can be persisted on disk, while keeping the same properties of superchunks in memory.  Finally, a metalayer capability allow for higher level containers to be created on top of superchunks/frames.&lt;/p&gt;
&lt;section id="highligths"&gt;
&lt;h3&gt;Highligths&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Maskout functionality.  This allows for selectively choose the blocks of a chunk that are going to be decompressed.  This paves the road for faster multidimensional slicing in Caterva (see below in the Caterva section).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Prefilters introduced and declared stable.  Prefilters allow for the user to pass C functions for performing arbitrary computations on a chunk prior to the filter/codec pipeline.  In addition, the C function can even have access to more chunks than just the one that is being compressed.  This opens the door to a way to operate with different super-chunks and produce a new one very efficiently. See &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/master/tests/test_prefilter.c"&gt;https://github.com/Blosc/c-blosc2/blob/master/tests/test_prefilter.c&lt;/a&gt; for some examples of use.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Support for PowerPC/Altivec.  We added support for PowerPC SIMD (Altivec/VSX) instructions for faster operation of shuffle and bitshuffle filters.  For details, see &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/pull/98"&gt;https://github.com/Blosc/c-blosc2/pull/98&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Improvements in compression ratio for LZ4/BloscLZ.  New processors are continually increasing the amount of memory in their caches.  In recent C-Blosc and C-Blosc2 releases we increased the size of the internal blocks so that LZ4/BloscLZ codecs have better opportunities for finding duplicates and hence, increasing their compression ratios.  But due to the increased cache sizes, performance has kept close to the original, fast speeds.  For some benchmarks, see &lt;a class="reference external" href="https://blosc.org/posts/beast-release/"&gt;https://blosc.org/posts/beast-release/&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;New entropy probing method for BloscLZ.  BloscLZ is a native codec for Blosc whose mission is to be able to compress synthetic data efficiently.  Synthetic data can appear in multiple situations and having a codec that is meant to compress/decompress that with high compression ratios in a fast manner is important.  The new entropy probing method included in recent BloscLZ 2.3 (introduced in both C-Blosc and C-Blosc2) allows for even better compression ratios for highly compressible data, while giving up early when blocks are going to be difficult to compress at all.  For details see: &lt;a class="reference external" href="https://blosc.org/posts/beast-release/"&gt;https://blosc.org/posts/beast-release/&lt;/a&gt; too.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="roadmap-for-c-blosc2"&gt;
&lt;h3&gt;Roadmap for C-Blosc2&lt;/h3&gt;
&lt;p&gt;During the next few months, we plan to tackle the next tasks:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Postfilters.  The same way that prefilters allows to do user-defined computations prior to the compression pipeline, the postfilter would allow to do the same &lt;em&gt;after&lt;/em&gt; the decompression pipeline.  This could be useful in e.g. creating superchunks out of functions taking simple data as input (for example, a [min, max] range of values).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finalize the frame implementation.  Although the frame specification is almost complete (bar small modifications/additions), we still miss some features that are included in the specification, but not implemented yet.  An example of this is the fingerprint support at the end of the frames.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Chunk insertion.  Right now only chunk appends are supported.  It should be possible to support chunk insertion in any position, and not only at the end of a superchunk.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Security.  Although we already started actions to improve the safety of the package using tools like OSS-Fuzz, this is an always work in progress task, and we plan indeed continuing improving it in the future.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Wheels.  We would like to deliver wheels on every release soon.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="caterva-cat4py"&gt;
&lt;h2&gt;Caterva/cat4py&lt;/h2&gt;
&lt;p&gt;Caterva is a multidimensional container on top of C-Blosc2 containers.  It uses the metalayer capabilities present in superchunks/frames in order to store the multidimensionality information necessary to define arrays up to 8 dimensions and up to 2^63 elements.  Besides being able to create such arrays, Caterva provides functionality to get (multidimensional) slices of the arrays easyly and efficiently.  cat4py is the Python wrapper for Caterva.&lt;/p&gt;
&lt;section id="id1"&gt;
&lt;h3&gt;Highligths&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Multidimensional blocks.  Chunks inside superchunk containers are endowed with a multidimensional structure so as to enable efficient slicing.  However, in many cases there is a tension between defining large chunks so as to reduce the amount of indexing to find chunks or smaller ones in order to avoid reading data that falls outside of a slice.  In order to reduce such a tension, we endowed the blocks inside chunks with a multidimensional structure too, so that the user has two parameters (chunkshape and blockshape) to play with in order to optimize I/O for their use case.  For an example of the kind of performance enhancements you can expect, see &lt;a class="reference external" href="https://htmlpreview.github.io/?https://github.com/Blosc/cat4py/blob/269270695d7f6e27e6796541709e98e2f67434fd/notebooks/slicing-performance.html"&gt;https://htmlpreview.github.io/?https://github.com/Blosc/cat4py/blob/269270695d7f6e27e6796541709e98e2f67434fd/notebooks/slicing-performance.html&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;API refactoring.  Caterva is a relatively young project, and its API grew up organically and hence, in a quite disorganized manner.  We recognized that and proceeded with a big API refactoring, trying to put more sense in the naming schema of the functions, as well as in providing a minimal set of C structs that allows for a simpler and better API.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Improved documentation.  A nice API is useless if it is not well documented, so we decided to put a significant amount of effort in creating high-quality documentation and examples so that the user can quickly figure out how to create and access Caterva containers with their own data.  Although this is still a work in progress, we are pretty happy with how docs are shaping up.  See &lt;a class="reference external" href="https://caterva.readthedocs.io/"&gt;https://caterva.readthedocs.io/&lt;/a&gt; and &lt;a class="reference external" href="https://cat4py.readthedocs.io/"&gt;https://cat4py.readthedocs.io/&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Better Python integration (cat4py).  Python, specially thanks to the NumPy project, is a major player in handling multidimensional datasets, so have greatly bettered the integration of cat4py, our Python wrapper for Caterva, with NumPy.  In particular, we implemented support for the NumPy array protocol in cat4py containers, as well as an improved NumPy-esque API in cat4py package.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="roadmap-for-caterva-cat4py"&gt;
&lt;h3&gt;Roadmap for Caterva / cat4py&lt;/h3&gt;
&lt;p&gt;During the next months, we plan to tackle the next tasks:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Append chunks in any order. This will make it easier for the user to create arrays, since they will not be forced to use a row-wise order.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update array elements. With this, users will be able to update their arrays without having to make a copy.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Resize array dimensions. This feature will allow Caterva to increase or decrease in size any dimension of the arrays.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Wheels.  Once Caterva/cat4py would be in beta stage, we plan to deliver wheels on every release.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="final-thoughts"&gt;
&lt;h2&gt;Final thoughts&lt;/h2&gt;
&lt;p&gt;We are very grateful to our sponsors in 2020; they allowed us to implement what we think would be nice features for the whole Blosc ecosystem.  However, and although we did a lot of progress towards making C-Blosc2 and Caterva as featured and stable as possible, we still need to finalize our efforts so as to see both projects stable enough to allow them to be used in production.  Our expectation is to release a 2.0.0 (final) release for C-Blosc2 by the end of the year, whereas Caterva (and cat4py) should be declared stable during 2021.&lt;/p&gt;
&lt;p&gt;Also, we are happy to have enrolled new members on Blosc crew: Óscar Griñón, who proved to be instrumental in implementing the multidimensional blocks in Caterva and Nathan Moinvaziri, who is making great strides in making C-Blosc and C-Blosc2 more secure.  Thanks guys!&lt;/p&gt;
&lt;p&gt;Hopefully 2021 will also be a good year for seeing the Blosc ecosystem to evolve.  If you are interested on what we are building and want to help, we are open to any kind of contribution, including &lt;a class="reference external" href="https://blosc.org/pages/donate/"&gt;donations&lt;/a&gt;.  Thank you for your interest!&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>blosc progress report grants</category><guid>http://blosc.org/posts/mid-2020-progress-report/</guid><pubDate>Thu, 27 Aug 2020 12:32:20 GMT</pubDate></item><item><title>C-Blosc Beast Release</title><link>http://blosc.org/posts/beast-release/</link><dc:creator>Francesc Alted</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;strong&gt;TL;DR;&lt;/strong&gt; The improvements in new CPUs allow for more cores and (much) larger caches. Latest C-Blosc release leverages these facts so as to allow better compression ratios, while keeping the speed on par with previous releases.&lt;/p&gt;
&lt;p&gt;During the past two months we have been working hard at increasing the efficiency of Blosc for the new processors that are coming with more cores than ever before (8 can be considered quite normal, even for laptops, and 16 is not that unusual for rigs).  Furthermore, their caches are increasing beyond limits that we thought unthinkable just a few years ago (for example, AMD is putting 64 MB in L3 for their mid-range Ryzen2 39x0 processors).  This is mainly a consequence of the recent introduction of the 7nm process for both ARM and AMD64 architectures.  It turns out that compression ratios are quite dependent on the sizes of the streams to compress, so having access to more cores and significantly larger caches, it was clear that Blosc was in a pressing need to catch-up and fine-tune its performance for such a new 'beasts'.&lt;/p&gt;
&lt;p&gt;So, the version released today (&lt;a class="reference external" href="https://github.com/Blosc/c-blosc/releases/tag/v1.20.0"&gt;C-Blosc 1.20.0&lt;/a&gt;) has been carefully fine-tuned to take the most of recent CPUs, specially for fast codecs, where even if speed is more important than compression ratio, the latter is still a very important parameter.  With that, we decided to increase the amount of every compressed stream in a block from 64 KB to 256 KB (most of CPUs nowadays have this amount of private L2 cache or even larger).   Also, it is important to allow a minimum of shared L3 cache to every thread so that they do not have to compete for resources, so a new restriction has been added so that no thread has to deal with streams larger than 1 MB (both old and modern CPUs seem to guarantee that they provide at least this amount of L3 per thread).&lt;/p&gt;
&lt;p&gt;Below you will find the net effects of this new fine-tuning of fast codecs like LZ4 and BloscLZ on our AMD 3900X box (12 physical cores, 64 MB L3).  Here we will be comparing results from C-Blosc 1.18.1 and C-Blosc 1.20.0 (we will skip the comparison against 1.19.x because this can be considered an intermediate release in our pursuit).  Spoiler: you will be seeing an important boost of compression ratios, while the high speed of LZ4 and BloscLZ codecs is largely kept.&lt;/p&gt;
&lt;p&gt;On the plots below, on the left is the performance of 1.18.1 release, whereas on the right is the performance of the new 1.20.0 release.&lt;/p&gt;
&lt;section id="effects-in-lz4"&gt;
&lt;h2&gt;Effects in LZ4&lt;/h2&gt;
&lt;p&gt;Let's start by looking at how the new fine tuning affected &lt;em&gt;compression&lt;/em&gt; performance:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style="width: 52%"&gt;
&lt;col style="width: 48%"&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;img alt="lz4-c-before" src="http://blosc.org/images/beast-release/ryzen12-lz4-1.18.1-c.png"&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;img alt="lz4-c-after" src="http://blosc.org/images/beast-release/ryzen12-lz4-1.20.0-c.png"&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Look at how much compression ratio has improved.  This is mainly a consequence of using compression streams of up to 256 KB, instead of the previous 64 KB --incidentally, this is just for this synthetic data, but it is clear that real data is going to be benefited as well; besides, synthetic data is something that frequently appears in data science (e.g. a uniformly spaced array of values).  One can also see that compression speed has not dropped in general which is great considering that we allow for much better compression ratios now.&lt;/p&gt;
&lt;p&gt;Regarding decompression we can see a similar pattern:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style="width: 52%"&gt;
&lt;col style="width: 48%"&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;img alt="lz4-d-before" src="http://blosc.org/images/beast-release/ryzen12-lz4-1.18.1-d.png"&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;img alt="lz4-d-after" src="http://blosc.org/images/beast-release/ryzen12-lz4-1.20.0-d.png"&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So the decompression speed is generally the same, even for data that can be compressed with high compression ratios.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="effects-in-blosclz"&gt;
&lt;h2&gt;Effects in BloscLZ&lt;/h2&gt;
&lt;p&gt;Now it is the turn for BloscLZ.  Similarly to LZ4, this codec is also meant for speed, but another reason for its existence is that it usually provides better compression ratios than LZ4 when using synthetic data.  In that sense, BloscLZ complements well LZ4 because the latter can be used for real data, whereas BloscLZ is usually a better bet for highly repetitive synthetic data.  In new C-Blosc we have introduced BloscLZ 2.3.0 which brings a brand new entropy detector which will disable compression early when entropy is high, allowing to selectively put CPU cycles where there are more low-hanging data compression opportunities.&lt;/p&gt;
&lt;p&gt;Here it is how performance changes for &lt;em&gt;compression&lt;/em&gt;:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style="width: 51%"&gt;
&lt;col style="width: 49%"&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;img alt="blosclz-c-before" src="http://blosc.org/images/beast-release/ryzen12-blosclz-1.18.1-c.png"&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;img alt="blosclz-c-after" src="http://blosc.org/images/beast-release/ryzen12-blosclz-1.20.0-c.png"&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In this case, the compression ratio has improved a lot too, and even if compression speed suffers a bit for small compression levels, it is still on par to the original speed for higher compression levels (compressing at more than 30 GB/s while reaching large compression ratios is a big achievement indeed).&lt;/p&gt;
&lt;p&gt;Regarding decompression we have this:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style="width: 51%"&gt;
&lt;col style="width: 49%"&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;img alt="blosclz-d-before" src="http://blosc.org/images/beast-release/ryzen12-blosclz-1.18.1-d.png"&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;img alt="blosclz-d-after" src="http://blosc.org/images/beast-release/ryzen12-blosclz-1.20.0-d.png"&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As usual for the new release, the decompression speed is generally the same, and performance can still exceed 80 GB/s for the whole range of compression levels.  Also noticeable is that fact that single-thread speed is pretty competitive with a regular &lt;cite&gt;memcpy()&lt;/cite&gt;.  Again, Ryzen2 architecture is showing its muscle here.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="final-thoughts"&gt;
&lt;h2&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;Due to technological reasons, CPUs are evolving towards having more cores and larger caches.  Hence, compressors and specially Blosc, has to adapt to the new status quo.  With the new parametrization and new algorithms (early entropy detector) introduced today, we can achieve much better results.  In new Blosc you can expect a good bump in compression ratios with fast codecs (LZ4, BloscLZ) while keeping speed as good as always.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="appendix-hardware-and-software-used"&gt;
&lt;h2&gt;Appendix: Hardware and Software Used&lt;/h2&gt;
&lt;p&gt;For reference, here it is the software that has been used for this blog entry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hardware&lt;/strong&gt;: AMD Ryzen2 3900X, 12 physical cores, 64 MB L3, 32 GB RAM.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OS&lt;/strong&gt;: Ubuntu 20.04&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Compiler&lt;/strong&gt;: Clang 10.0.0&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;C-Blosc&lt;/strong&gt;: 1.18.1 (2020-03-29) and 1.20.0 (2020-07-25)&lt;/p&gt;
&lt;p&gt;** Enjoy Data!**&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>blosc performance tuning</category><guid>http://blosc.org/posts/beast-release/</guid><pubDate>Sat, 25 Jul 2020 14:32:20 GMT</pubDate></item><item><title>Blosc Received a $50,000 USD donation</title><link>http://blosc.org/posts/blosc-donation/</link><dc:creator>Francesc Alted</dc:creator><description>&lt;div&gt;&lt;p&gt;I am happy to announce that the Blosc project recently received a donation of $50,000 USD from Huawei via NumFOCUS.  Now that we have such an important amount available, our plan is to use it in order to continue making Blosc and its ecosystem more useful for the community.  In order to do so, it is important to stress out that our priorities are going to be on the fundamentals of the stack: getting &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2"&gt;C-Blosc2&lt;/a&gt; out of beta and pushing for making &lt;a class="reference external" href="https://github.com/Blosc/Caterva"&gt;Caterva&lt;/a&gt; (the multi-dimensional container on top of C-Blosc2) actually usable.&lt;/p&gt;
&lt;section id="critical-tasks-pushing-c-blosc2-and-caterva"&gt;
&lt;h2&gt;Critical Tasks: Pushing C-Blosc2 and Caterva&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/Blosc/c-blosc2"&gt;C-Blosc2&lt;/a&gt; has been kind of a laboratory that we used for testing new ideas, like new 64-bit containers, new filters, a new serialization system, the concept of pre-filters and others, for the past 5 years.  Although the fork from C-Blosc happened such a long time ago, we tried hard to keep the API backwards compatible so that C-Blosc2 can be used as a drop-in replacement of C-Blosc1 --but beware, the C-Blosc2 format will not be forward-compatible with C-Blosc1, but will be backward-compatible, that is, it will be able to read C-Blosc1 compressed chunks.&lt;/p&gt;
&lt;p&gt;On its hand, &lt;a class="reference external" href="https://github.com/Blosc/Caterva"&gt;Caterva&lt;/a&gt; is our attempt to build a multidimensional container that is tightly built on top of C-Blosc2, so leveraging its unique features.  Caterva is a C99 library (the same than C-Blosc2) that will allow an easy adoption by many different libraries that are about matrix manipulation.  The fact that it supports on-the-flight compression and persistency will open new possibilities in that the size of matrices will not be limited to the available memory anymore: data may span through available memory &lt;em&gt;or&lt;/em&gt; disk in &lt;em&gt;compressed&lt;/em&gt; state.&lt;/p&gt;
&lt;p&gt;Provided how fundamental C-Blosc2 and Caterva packages are meant to be, we think that the usefulness of the Blosc project as a whole will be largely benefited from putting most of our efforts here for the next months/years.  For this, we already established a series of priorities for working in these projects, as specified in the roadmaps below&lt;/p&gt;
&lt;/section&gt;
&lt;section id="roadmap-for-c-blosc2"&gt;
&lt;h2&gt;Roadmap for C-Blosc2&lt;/h2&gt;
&lt;p&gt;C-Blosc2 is already in beta stage, and in the next few months we should see it in production stage.  Here are some of the more important the things that we want to tackle in order to make this happen:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Plugin capabilities for allowing users to add more filters and codecs. There should also be a plugin register capability so that the info about the new filters and codecs can be persistent and propagated to different machines.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Checksums: the frame can benefit from having a checksum per every chunk/index/metalayer. This will provide more safety towards frames that are damaged for whatever reason. Also, this would provide better feedback when trying to determine the parts of the frame that are corrupted.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Documentation: utterly important for attracting new users and making the life easier for existing ones. Important points to have in mind here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Quality of API docstrings: is the mission of the functions or data structures clearly and succinctly explained? Are all the parameters explained? Is the return value explained? What are the possible errors that can be returned?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tutorials/book: besides the API docstrings, more documentation materials should be provided, like tutorials or a book about Blosc (or at least, the beginnings of it). Due to its adoption in GitHub and Jupyter notebooks, one of the most extended and useful markup systems is MarkDown, so this should also be the first candidate to use here.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Wrappers for other languages: Python and Java are the most obvious candidates, but others like R or Julia would be nice to have. Still not sure if these should be produced and maintained by the Blosc development team, or leave them for third-party players that would be interested.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a more detailed discussion see: &lt;a class="reference external" href="https://github.com/Blosc/c-blosc2/blob/master/ROADMAP.md"&gt;https://github.com/Blosc/c-blosc2/blob/master/ROADMAP.md&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;section id="roadmap-for-caterva"&gt;
&lt;h2&gt;Roadmap for Caterva&lt;/h2&gt;
&lt;p&gt;Caterva is a much more young project and as such, one may say that it is still in alpha stage, although the basic functionality like creating multidimensional containers, getting items or multidimensional slices or accessing persistent data without a previous load is already there.  However, we still miss important things like:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;A complete refactorization of the Caterva C code to facilitate its usability.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adapt the Python interface to the refactorization done in C code.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add examples into the Python wrapper documentation and create some jupyter notebooks.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Build wheels to make the Python wrapper easier for the user.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Implements a new level of multidimensionality in Caterva. After that, we will support three layers of multidimensionality in a Caterva container: the shape, the chunk shape and the block shape.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a more detailed discussion see: &lt;a class="reference external" href="https://github.com/Blosc/Caterva/blob/master/ROADMAP.md"&gt;https://github.com/Blosc/Caterva/blob/master/ROADMAP.md&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;section id="how-we-are-spending-resources"&gt;
&lt;h2&gt;How we are spending resources&lt;/h2&gt;
&lt;p&gt;Money is important, but not everything: you need people to work on a project.  We are slowly starting to put consistent human resources in the Blosc project.  To start with, I (Francesc Alted) and Aleix Alcacer will be putting 25% of our time in the project for the next months, and hopefully others will join too.  We will also be using funds to invest in our main tool, that is laptops and desktop computers, but also some furniture like proper seats and tables; the office space is important for creating a happy team.  Finally, our plan is to use a part of the donation in facilitating meeting among the Blosc development team.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="your-input-is-important-for-us"&gt;
&lt;h2&gt;Your input is important for us&lt;/h2&gt;
&lt;p&gt;Although during the next year or so, we plan to organize some meetings of the board of directors and the Blosc development team, we think that our ideas cannot grow isolated from the community of users.  So in case you want to convey ideas or better, contribute with &lt;em&gt;implementation&lt;/em&gt; of ideas, we will be happy to hear and discuss.  You can get in touch with us via the Blosc mailing list (&lt;a class="reference external" href="https://groups.google.com/forum/#!forum/blosc"&gt;https://groups.google.com/forum/#!forum/blosc&lt;/a&gt;), and the @Blosc2 twitter account.  We are thinking that having other tools like Discourse may help in driving discussions more to the point, but so far we have little experience with it; if you have other suggestions please tell us.&lt;/p&gt;
&lt;p&gt;All in all, the Blosc development team is very excited about this new development, and we are putting all our enthusiasm for delivering a new set of tools that we sincerely hope will of of help for the data community out there.&lt;/p&gt;
&lt;p&gt;Finally, let me thank our main sponsor for their generous donation, NumFOCUS for accepting our project inside its umbrella, and to all the users and contributors that made Blosc and its ecosystem to help people through the past years (a bit more than 10 since the first C-Blosc 1.0 release).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Enjoy Data!&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>donation blosc2 caterva</category><guid>http://blosc.org/posts/blosc-donation/</guid><pubDate>Thu, 20 Feb 2020 01:32:20 GMT</pubDate></item><item><title>Blosc2-Meets-Rome</title><link>http://blosc.org/posts/blosc2-meets-rome/</link><dc:creator>Francesc Alted</dc:creator><description>&lt;div&gt;&lt;p&gt;On August 7, 2019, AMD released a new generation of its series of EPYC processors, the EPYC 7002, also known as Rome, which are based on the new &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Zen_2"&gt;Zen 2&lt;/a&gt; micro-architecture.  Zen 2 is a significant departure from the physical design paradigm of AMD's previous Zen architectures, mainly in that the I/O components of the CPU are laid out on a separate die, different from computing dies; this is quite different from Naples (aka EPYC 7001), its antecessor in the EPYC series:&lt;/p&gt;
&lt;img alt="/images/blosc2-meets-rome/amd-rome-arch-multi-die.png" class="align-center" src="http://blosc.org/images/blosc2-meets-rome/amd-rome-arch-multi-die.png"&gt;
&lt;p&gt;Such a separation of dies for I/O and computing has quite &lt;a class="reference external" href="https://www.anandtech.com/show/15044/the-amd-ryzen-threadripper-3960x-and-3970x-review-24-and-32-cores-on-7nm/3"&gt;large consequences in terms of scalability when accessing memory&lt;/a&gt;, which is critical for Blosc operation, and here we want to check how Blosc and AMD Rome couple behaves.  As there is no replacement for experimentation, we are going to use the same benchmark that was introduced in our previous &lt;a class="reference external" href="https://blosc.org/posts/breaking-memory-walls/"&gt;Breaking Down Memory Walls&lt;/a&gt;.  This essentially boils down to compute an aggregation with a simple loop like:&lt;/p&gt;
&lt;pre class="code c"&gt;&lt;a id="rest_code_69dbd16fb52b4260817da0d569c9366f-1" name="rest_code_69dbd16fb52b4260817da0d569c9366f-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#pragma omp parallel for reduction (+:sum)&lt;/span&gt;
&lt;a id="rest_code_69dbd16fb52b4260817da0d569c9366f-2" name="rest_code_69dbd16fb52b4260817da0d569c9366f-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_69dbd16fb52b4260817da0d569c9366f-3" name="rest_code_69dbd16fb52b4260817da0d569c9366f-3"&gt;&lt;/a&gt;  &lt;span class="n"&gt;sum&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;udata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;a id="rest_code_69dbd16fb52b4260817da0d569c9366f-4" name="rest_code_69dbd16fb52b4260817da0d569c9366f-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;As described in the original blog post, the different &lt;cite&gt;udata&lt;/cite&gt; arrays are just chunks of the original dataset that are decompressed just in time for performing the partial aggregation operation; the final result is indeed the sum of all the partial aggregations.  Also we have seen that the time to execute the aggregation is going to depend quite a lot on the kind of data that is decompressed: carefully chosen synthetic data can be decompressed much more quickly than real data.  But syntehtic data is nevertheless interesting as it allows for a roof analysis of where the performance can grow up to.&lt;/p&gt;
&lt;p&gt;In this blog, we are going to see how the AMD EPYC 7402 (Rome), a 24-core processor performs on both synthetic and real data.&lt;/p&gt;
&lt;section id="aggregating-the-synthetic-dataset-on-amd-epyc-7402-24-core"&gt;
&lt;h2&gt;Aggregating the Synthetic Dataset on AMD EPYC 7402 24-Core&lt;/h2&gt;
&lt;p&gt;The synthetic data chosen for this benchmark allows to be compressed/decompressed very easily with applying the shuffle filter before the actual compression codec.  Interestingly, and as good example of how filters can benefit the compression process, if we would not apply the shuffle filter first, synthetic data was going to take much more time to compress/decompress (test it by yourself if you don't believe this).&lt;/p&gt;
&lt;p&gt;After some experiments, and as usual for synthetic datasets, the codec inside Blosc2 that has shown the best speed while keeping a decent compression ratio (54.6x), has been BloscLZ with compression level 3.  Here are the results:&lt;/p&gt;
&lt;img alt="/images/blosc2-meets-rome/sum_openmp_synthetic-blosclz-3.png" class="align-center" src="http://blosc.org/images/blosc2-meets-rome/sum_openmp_synthetic-blosclz-3.png"&gt;
&lt;p&gt;As we can see, the uncompressed dataset scales pretty well until 8 threads, where it hits the memory wall for this machine (around 74 GB/s).  On its hand, even if data compressed with Blosc2 (in combination with BloscLZ codec) shows less performance initially, it scales quite smoothly up to 12 threads, where it reaches a higher performance than its uncompressed counterpart (and reaching the 90 GB/s mark).&lt;/p&gt;
&lt;p&gt;After that, the compressed dataset can perform aggregations at speeds that are typically faster than uncompressed ones, reaching important peaks at some magical number of threads (up to 210 GB/s at 48 threads).  Why these peaks exist at all is probably related with the architecture of the AMD Rome processor, but provided that we are using a 24-core CPU there is little wonder that numbers like 12, 24 (28 is an exception here) and 48 are reaching the highest figures.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="aggregating-the-precipitation-dataset-on-amd-epyc-7402-24-core"&gt;
&lt;h2&gt;Aggregating the Precipitation Dataset on AMD EPYC 7402 24-Core&lt;/h2&gt;
&lt;p&gt;Now it is time to check the performance of the aggregation with the 100 million values dataset coming from a &lt;a class="reference external" href="http://reanalysis.meteo.uni-bonn.de/"&gt;precipitation dataset from Central Europe&lt;/a&gt;.  Computing the aggregation of this data is representative of a catchment average of precipitation over a drainage area.  This time, the best codec inside Blosc2 was determined to be LZ4 with compression level 9:&lt;/p&gt;
&lt;img alt="/images/blosc2-meets-rome/sum_openmp_rainfall-lz4-9-lz4-9-ipp.png" class="align-center" src="http://blosc.org/images/blosc2-meets-rome/sum_openmp_rainfall-lz4-9-lz4-9-ipp.png"&gt;
&lt;p&gt;As expected, the uncompressed aggregation scales pretty much the same than for the synthetic dataset (in the end, the Arithmetic and Logical Unit in the CPU is completely agnostic on what kind of data it operates with).  But on its hand, the compressed dataset scales more slowly, but more steadily towards hitting a maximum at 48 threads, where it reaches almost the same speed than the uncompressed dataset, which is quite a feat, provided the high memory bandwidth of this machine (~74 GB/s).&lt;/p&gt;
&lt;p&gt;Also, as Blosc2 recently gained support for the  &lt;a class="reference external" href="https://blosc.org/posts/blosc2-first-beta/"&gt;accelerated LZ4 codec inside Intel IPP&lt;/a&gt;, figures for it have been added to the plot above.  There one can see that Intel's accelerated LZ4 can get an up to 10% boost in speed compared with regular LZ4; this additional 10% actually allows Blosc2/LZ4 to be clearly faster than the uncompressed dataset at 48 threads.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="final-thoughts"&gt;
&lt;h2&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;AMD EPYC Rome represents a significant leap forward in adding a high number of cores to CPUs in a way that scales really well, allowing to put more computational resources to our problems at hand.  Here we have shown how nicely a 24-core AMD Rome CPU performs when performing tasks with in-memory compressed datasets; first, by allowing competitive speed when using compression with real data and second, allowing speeds of more than 200 GB/s (with synthetic datasets).&lt;/p&gt;
&lt;p&gt;Finally, the 24-core CPU that we have exercised here is just for whetting your appetite, as CPUs of 32 or even 64 cores are going to happen more and more often in the next future.  Although I should have better said in &lt;em&gt;present times&lt;/em&gt;, as &lt;a class="reference external" href="https://www.anandtech.com/show/15044/the-amd-ryzen-threadripper-3960x-and-3970x-review-24-and-32-cores-on-7nm"&gt;AMD announced today the availability of 32-core CPUs for the workstation market&lt;/a&gt;, with 64-core ones coming next year.  Definitely, compression is going to play an increasingly important role in getting the most out of these beasts.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="appendix-software-used"&gt;
&lt;h2&gt;Appendix: Software used&lt;/h2&gt;
&lt;p&gt;For reference, here it is the software that has been used for this blog entry:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;OS&lt;/strong&gt;: Ubuntu 19.10&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Compiler&lt;/strong&gt;: Clang 8.0.0&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;C-Blosc2&lt;/strong&gt;: 2.0.0b5.dev (2019-09-13)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="acknowledgments"&gt;
&lt;h2&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Thanks to &lt;a class="reference external" href="https://www.packet.com"&gt;packet.com&lt;/a&gt; for kindly providing the hardware for the purposes of this benchmark.  Packet guys have been really collaborative through the time in allowing me testing new, bare-metal hardware, and I must say that I am quite impressed on how easy is to start using their services with almost no effort on user's side.&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;</description><category>amd</category><category>memory wall</category><category>rome</category><guid>http://blosc.org/posts/blosc2-meets-rome/</guid><pubDate>Mon, 25 Nov 2019 18:32:20 GMT</pubDate></item></channel></rss>